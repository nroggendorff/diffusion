{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00024a7-3761-4e53-9e4e-38b15a24fb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbb82ea-8ac7-4324-b921-1fb41808cf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/user/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0f59df-509e-4e5a-961d-0d9970249235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27/2024 20:13:47 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "{'sample_max_value', 'variance_type', 'thresholding', 'rescale_betas_zero_snr', 'timestep_spacing', 'clip_sample_range', 'dynamic_thresholding_ratio', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor', 'force_upcast', 'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type_num_heads', 'time_embedding_type', 'upcast_attention', 'dropout', 'mid_block_type', 'class_embed_type', 'resnet_time_scale_shift', 'transformer_layers_per_block', 'resnet_out_scale_factor', 'addition_time_embed_dim', 'use_linear_projection', 'only_cross_attention', 'reverse_transformer_layers_per_block', 'time_embedding_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'mid_block_only_cross_attention', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'dual_cross_attention', 'cross_attention_norm', 'attention_type', 'addition_embed_type', 'resnet_skip_time_act', 'num_attention_heads', 'encoder_hid_dim', 'conv_in_kernel', 'time_embedding_act_fn', 'conv_out_kernel', 'encoder_hid_dim_type'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type_num_heads', 'time_embedding_type', 'upcast_attention', 'dropout', 'mid_block_type', 'class_embed_type', 'resnet_time_scale_shift', 'transformer_layers_per_block', 'resnet_out_scale_factor', 'addition_time_embed_dim', 'use_linear_projection', 'only_cross_attention', 'reverse_transformer_layers_per_block', 'time_embedding_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'mid_block_only_cross_attention', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'dual_cross_attention', 'cross_attention_norm', 'attention_type', 'addition_embed_type', 'resnet_skip_time_act', 'num_attention_heads', 'encoder_hid_dim', 'conv_in_kernel', 'time_embedding_act_fn', 'conv_out_kernel', 'encoder_hid_dim_type'} was not found in config. Values will be initialized to default values.\n",
      "04/27/2024 20:13:52 - INFO - __main__ - ***** Running training *****\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Num examples = 108\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Num Epochs = 139\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "04/27/2024 20:13:52 - INFO - __main__ -   Total optimization steps = 15000\n",
      "Steps:   0%|                                          | 0/15000 [00:00<?, ?it/s]/home/user/miniconda/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "Steps:   0%|       | 23/15000 [00:09<1:25:38,  2.91it/s, lr=0.01, step_loss=nan]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/train.py\", line 1097, in <module>\n",
      "    main()\n",
      "  File \"/data/train.py\", line 978, in main\n",
      "    accelerator.backward(loss)\n",
      "  File \"/home/user/miniconda/lib/python3.9/site-packages/accelerate/accelerator.py\", line 2011, in backward\n",
      "    self.scaler.scale(loss).backward(**kwargs)\n",
      "  File \"/home/user/miniconda/lib/python3.9/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/user/miniconda/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/user/miniconda/lib/python3.9/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Steps:   0%|       | 23/15000 [00:10<1:51:13,  2.24it/s, lr=0.01, step_loss=nan]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train.py --mixed_precision \"fp16\" --gradient_accumulation_steps 1 --learning_rate \"1e-02\" --gradient_checkpointing --max_grad_norm 1 --checkpointing_steps 100000 --max_train_steps=15000 --use_ema --lr_scheduler \"constant\" --lr_warmup_steps 0 --center_crop --random_flip --pretrained_model_name_or_path \"runwayml/stable-diffusion-v1-5\" --dataset_name \"nroggendorff/zelda\" --resolution 512 --train_batch_size 1 --output_dir \"sd-zelda-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb811021-5f43-4193-95d1-f149f9d359ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_folder, notebook_login, create_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b7e44-6190-4348-a7c1-05bb800aa29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961a7b6-3428-42a8-afbf-0ce629642072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_id = create_repo(\n",
    "    repo_id=\"nroggendorff/zelda-diffusion\", exist_ok=True\n",
    ").repo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862e27a-6d24-48ab-9626-4e1219a53963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    folder_path=\"sd-zelda-model\",\n",
    "    commit_message=f\"Steps 10k\",\n",
    "    ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8bd67-c78c-456b-a913-0123fccad040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"sd-zelda-model\", torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n",
    "\n",
    "image = pipeline(prompt=\"a woman holding a sword\").images[0]\n",
    "image.save(\"zelda.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
